{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vupadhayayula/Speech_Processing_LTRC/blob/main/Emotion_recognition_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJBerAGb-dei",
        "outputId": "8cebbf00-b494-4cbd-bb0a-aaf15c53391d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFQckm56R4Q",
        "outputId": "c186b887-6a2c-4402-ca8d-968f1e8d9e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading toronto-emotional-speech-set-tess.zip to /content\n",
            " 97% 417M/428M [00:02<00:00, 160MB/s]\n",
            "100% 428M/428M [00:03<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QggmgicI6d8E"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/toronto-emotional-speech-set-tess.zip')\n",
        "zip_ref.extractall('/content/drive/MyDrive/emotion')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQCMefBx6gKd",
        "outputId": "e97e0e6d-9b9a-46de-899d-2315b0707dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2800\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "voice = glob.glob('/content/drive/MyDrive/emotion/TESS Toronto emotional speech set data/**/*.wav',recursive=True)\n",
        "print(len(voice))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vNLB0etAS4Q",
        "outputId": "db6483a9-e8fd-476d-c724-f2b1ac8ecd51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OAF_Fear',\n",
              " 'OAF_Pleasant_surprise',\n",
              " 'OAF_Sad',\n",
              " 'OAF_angry',\n",
              " 'OAF_disgust',\n",
              " 'OAF_happy',\n",
              " 'OAF_neutral',\n",
              " 'YAF_angry',\n",
              " 'YAF_disgust',\n",
              " 'YAF_fear',\n",
              " 'YAF_happy',\n",
              " 'YAF_neutral',\n",
              " 'YAF_pleasant_surprised',\n",
              " 'YAF_sad']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "os.listdir(\"/content/drive/MyDrive/emotion/TESS Toronto emotional speech set data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsNg24ipAkNo"
      },
      "outputs": [],
      "source": [
        "parent_dir = \"/content/drive/MyDrive/emotion/TESS Toronto emotional speech set data\"\n",
        "speaker_folders = [\n",
        "    \"OAF_Fear\",\n",
        "    \"OAF_Pleasant_surprise\",\n",
        "    'OAF_Sad',\n",
        "    'OAF_angry',\n",
        "    'OAF_disgust',\n",
        "    'OAF_happy',\n",
        "    'OAF_neutral',\n",
        "    'YAF_angry',\n",
        "    'YAF_disgust',\n",
        "    'YAF_fear',\n",
        "    'YAF_happy',\n",
        "    'YAF_neutral',\n",
        "    'YAF_pleasant_surprised',\n",
        "    'YAF_sad'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq5WMvEsAtBc",
        "outputId": "8a525c38-bfd1-4161-d84b-3eaba555ba03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 129, 64)           20736     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                910       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58830 (229.80 KB)\n",
            "Trainable params: 58830 (229.80 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "56/56 [==============================] - 15s 196ms/step - loss: 2.5983 - accuracy: 0.1390 - val_loss: 2.5354 - val_accuracy: 0.1250\n",
            "Epoch 2/60\n",
            "56/56 [==============================] - 6s 106ms/step - loss: 2.4701 - accuracy: 0.1535 - val_loss: 2.3580 - val_accuracy: 0.1763\n",
            "Epoch 3/60\n",
            "56/56 [==============================] - 9s 158ms/step - loss: 2.2994 - accuracy: 0.2143 - val_loss: 2.1529 - val_accuracy: 0.2969\n",
            "Epoch 4/60\n",
            "56/56 [==============================] - 7s 121ms/step - loss: 2.0770 - accuracy: 0.2958 - val_loss: 1.9148 - val_accuracy: 0.3862\n",
            "Epoch 5/60\n",
            "56/56 [==============================] - 7s 125ms/step - loss: 1.8875 - accuracy: 0.3744 - val_loss: 1.7405 - val_accuracy: 0.4107\n",
            "Epoch 6/60\n",
            "56/56 [==============================] - 8s 142ms/step - loss: 1.7189 - accuracy: 0.4191 - val_loss: 1.5889 - val_accuracy: 0.4665\n",
            "Epoch 7/60\n",
            "56/56 [==============================] - 6s 108ms/step - loss: 1.5430 - accuracy: 0.4771 - val_loss: 1.4873 - val_accuracy: 0.4866\n",
            "Epoch 8/60\n",
            "56/56 [==============================] - 9s 164ms/step - loss: 1.3986 - accuracy: 0.5100 - val_loss: 1.2827 - val_accuracy: 0.5647\n",
            "Epoch 9/60\n",
            "56/56 [==============================] - 6s 106ms/step - loss: 1.2967 - accuracy: 0.5502 - val_loss: 1.2325 - val_accuracy: 0.5580\n",
            "Epoch 10/60\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 1.1896 - accuracy: 0.5938 - val_loss: 1.0859 - val_accuracy: 0.6339\n",
            "Epoch 11/60\n",
            "56/56 [==============================] - 6s 106ms/step - loss: 1.0779 - accuracy: 0.6417 - val_loss: 0.9777 - val_accuracy: 0.6741\n",
            "Epoch 12/60\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.9701 - accuracy: 0.6836 - val_loss: 0.9168 - val_accuracy: 0.6897\n",
            "Epoch 13/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.9026 - accuracy: 0.6842 - val_loss: 1.0370 - val_accuracy: 0.6362\n",
            "Epoch 14/60\n",
            "56/56 [==============================] - 9s 155ms/step - loss: 1.0513 - accuracy: 0.6261 - val_loss: 0.8273 - val_accuracy: 0.7232\n",
            "Epoch 15/60\n",
            "56/56 [==============================] - 6s 109ms/step - loss: 0.8026 - accuracy: 0.7171 - val_loss: 0.7806 - val_accuracy: 0.7411\n",
            "Epoch 16/60\n",
            "56/56 [==============================] - 8s 143ms/step - loss: 0.7325 - accuracy: 0.7472 - val_loss: 0.7026 - val_accuracy: 0.7589\n",
            "Epoch 17/60\n",
            "56/56 [==============================] - 6s 109ms/step - loss: 0.7201 - accuracy: 0.7372 - val_loss: 0.6840 - val_accuracy: 0.7522\n",
            "Epoch 18/60\n",
            "56/56 [==============================] - 7s 132ms/step - loss: 0.6438 - accuracy: 0.7757 - val_loss: 0.6143 - val_accuracy: 0.7879\n",
            "Epoch 19/60\n",
            "56/56 [==============================] - 7s 119ms/step - loss: 0.6971 - accuracy: 0.7556 - val_loss: 0.7069 - val_accuracy: 0.7500\n",
            "Epoch 20/60\n",
            "56/56 [==============================] - 7s 121ms/step - loss: 0.6157 - accuracy: 0.7879 - val_loss: 0.5658 - val_accuracy: 0.7879\n",
            "Epoch 21/60\n",
            "56/56 [==============================] - 8s 135ms/step - loss: 0.5568 - accuracy: 0.8136 - val_loss: 0.5350 - val_accuracy: 0.8080\n",
            "Epoch 22/60\n",
            "56/56 [==============================] - 6s 107ms/step - loss: 0.5227 - accuracy: 0.8203 - val_loss: 0.5180 - val_accuracy: 0.8170\n",
            "Epoch 23/60\n",
            "56/56 [==============================] - 8s 147ms/step - loss: 0.4865 - accuracy: 0.8393 - val_loss: 0.5296 - val_accuracy: 0.7946\n",
            "Epoch 24/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.4671 - accuracy: 0.8482 - val_loss: 0.4848 - val_accuracy: 0.8281\n",
            "Epoch 25/60\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.4347 - accuracy: 0.8477 - val_loss: 0.4791 - val_accuracy: 0.8326\n",
            "Epoch 26/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.4022 - accuracy: 0.8666 - val_loss: 0.4612 - val_accuracy: 0.8348\n",
            "Epoch 27/60\n",
            "56/56 [==============================] - 9s 153ms/step - loss: 0.3968 - accuracy: 0.8700 - val_loss: 0.4562 - val_accuracy: 0.8237\n",
            "Epoch 28/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.3670 - accuracy: 0.8789 - val_loss: 0.4194 - val_accuracy: 0.8326\n",
            "Epoch 29/60\n",
            "56/56 [==============================] - 9s 158ms/step - loss: 0.3365 - accuracy: 0.8873 - val_loss: 0.4595 - val_accuracy: 0.8326\n",
            "Epoch 30/60\n",
            "56/56 [==============================] - 6s 115ms/step - loss: 0.3224 - accuracy: 0.8951 - val_loss: 0.4005 - val_accuracy: 0.8482\n",
            "Epoch 31/60\n",
            "56/56 [==============================] - 11s 204ms/step - loss: 0.2960 - accuracy: 0.9035 - val_loss: 0.3456 - val_accuracy: 0.8638\n",
            "Epoch 32/60\n",
            "56/56 [==============================] - 6s 109ms/step - loss: 0.2824 - accuracy: 0.8979 - val_loss: 0.3546 - val_accuracy: 0.8527\n",
            "Epoch 33/60\n",
            "56/56 [==============================] - 9s 156ms/step - loss: 0.2625 - accuracy: 0.9102 - val_loss: 0.3407 - val_accuracy: 0.8661\n",
            "Epoch 34/60\n",
            "56/56 [==============================] - 6s 112ms/step - loss: 0.2538 - accuracy: 0.9068 - val_loss: 0.4337 - val_accuracy: 0.8281\n",
            "Epoch 35/60\n",
            "56/56 [==============================] - 8s 139ms/step - loss: 0.2766 - accuracy: 0.9046 - val_loss: 0.3588 - val_accuracy: 0.8571\n",
            "Epoch 36/60\n",
            "56/56 [==============================] - 7s 117ms/step - loss: 0.2406 - accuracy: 0.9007 - val_loss: 0.3423 - val_accuracy: 0.8683\n",
            "Epoch 37/60\n",
            "56/56 [==============================] - 8s 139ms/step - loss: 0.2277 - accuracy: 0.9090 - val_loss: 0.2973 - val_accuracy: 0.8884\n",
            "Epoch 38/60\n",
            "56/56 [==============================] - 7s 121ms/step - loss: 0.2110 - accuracy: 0.9169 - val_loss: 0.3113 - val_accuracy: 0.8638\n",
            "Epoch 39/60\n",
            "56/56 [==============================] - 8s 136ms/step - loss: 0.2256 - accuracy: 0.9113 - val_loss: 0.2929 - val_accuracy: 0.8862\n",
            "Epoch 40/60\n",
            "56/56 [==============================] - 7s 124ms/step - loss: 0.2120 - accuracy: 0.9224 - val_loss: 0.2661 - val_accuracy: 0.8973\n",
            "Epoch 41/60\n",
            "56/56 [==============================] - 7s 117ms/step - loss: 0.2049 - accuracy: 0.9342 - val_loss: 0.3007 - val_accuracy: 0.8817\n",
            "Epoch 42/60\n",
            "56/56 [==============================] - 8s 139ms/step - loss: 0.1994 - accuracy: 0.9302 - val_loss: 0.3162 - val_accuracy: 0.8795\n",
            "Epoch 43/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.1754 - accuracy: 0.9414 - val_loss: 0.2736 - val_accuracy: 0.8906\n",
            "Epoch 44/60\n",
            "56/56 [==============================] - 8s 152ms/step - loss: 0.1494 - accuracy: 0.9537 - val_loss: 0.2851 - val_accuracy: 0.8906\n",
            "Epoch 45/60\n",
            "56/56 [==============================] - 6s 108ms/step - loss: 0.1396 - accuracy: 0.9621 - val_loss: 0.2531 - val_accuracy: 0.8996\n",
            "Epoch 46/60\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.1468 - accuracy: 0.9593 - val_loss: 0.2851 - val_accuracy: 0.8951\n",
            "Epoch 47/60\n",
            "56/56 [==============================] - 6s 112ms/step - loss: 0.1506 - accuracy: 0.9576 - val_loss: 0.2596 - val_accuracy: 0.9219\n",
            "Epoch 48/60\n",
            "56/56 [==============================] - 8s 152ms/step - loss: 0.1262 - accuracy: 0.9598 - val_loss: 0.2768 - val_accuracy: 0.9018\n",
            "Epoch 49/60\n",
            "56/56 [==============================] - 6s 109ms/step - loss: 0.1076 - accuracy: 0.9760 - val_loss: 0.2154 - val_accuracy: 0.9263\n",
            "Epoch 50/60\n",
            "56/56 [==============================] - 9s 162ms/step - loss: 0.1186 - accuracy: 0.9688 - val_loss: 0.2487 - val_accuracy: 0.9107\n",
            "Epoch 51/60\n",
            "56/56 [==============================] - 6s 110ms/step - loss: 0.1308 - accuracy: 0.9660 - val_loss: 0.2435 - val_accuracy: 0.9085\n",
            "Epoch 52/60\n",
            "56/56 [==============================] - 9s 153ms/step - loss: 0.1327 - accuracy: 0.9621 - val_loss: 0.2605 - val_accuracy: 0.8973\n",
            "Epoch 53/60\n",
            "56/56 [==============================] - 6s 109ms/step - loss: 0.1948 - accuracy: 0.9381 - val_loss: 0.3323 - val_accuracy: 0.8750\n",
            "Epoch 54/60\n",
            "56/56 [==============================] - 8s 141ms/step - loss: 0.1481 - accuracy: 0.9587 - val_loss: 0.2267 - val_accuracy: 0.9263\n",
            "18/18 [==============================] - 2s 36ms/step - loss: 0.2086 - accuracy: 0.9339\n",
            "\n",
            "Test accuracy: 0.9339285492897034\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "def extract_features(parent_dir, speaker_folders):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for i, speaker_folder in enumerate(speaker_folders):\n",
        "        speaker_folder_path = os.path.join(parent_dir, speaker_folder)\n",
        "        for filename in os.listdir(speaker_folder_path):\n",
        "            if filename.endswith(\".wav\"):\n",
        "                file_path = os.path.join(speaker_folder_path, filename)\n",
        "                audio, sr = librosa.load(file_path)\n",
        "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=16)\n",
        "                features.append(mfccs.T)\n",
        "                labels.append(i)\n",
        "    max_length = max(f.shape[0] for f in features)\n",
        "\n",
        "    padded_features = [np.pad(f, ((0, max_length - f.shape[0]), (0, 0)), mode='constant') for f in features]\n",
        "\n",
        "    return np.array(padded_features), np.array(labels)\n",
        "\n",
        "# Extract features and labels\n",
        "X, y = extract_features(parent_dir, speaker_folders)\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "# Reshape X_train, X_validation, and X_test for LSTM input\n",
        "timesteps = X_train.shape[1]  # Number of time steps\n",
        "features = X_train.shape[2]   # Number of features\n",
        "\n",
        "X_train = X_train.reshape(-1, timesteps, features)\n",
        "X_validation = X_validation.reshape(-1, timesteps, features)\n",
        "X_test = X_test.reshape(-1, timesteps, features)\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(64, input_shape=(timesteps, features), return_sequences=True))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.1))\n",
        "model.add(keras.layers.Dense(14, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_validation, y_validation),\n",
        "                    batch_size=32,\n",
        "                    epochs=60,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzReiAFQGnFi"
      },
      "outputs": [],
      "source": [
        "model.save(\"emotion_recognition_lstm.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnSJJunXHIc7",
        "outputId": "e8a8efd8-0123-49f3-bc2b-c1ffa55fe250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 129, 64)           20736     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 129, 64)           33024     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 14)                462       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93486 (365.18 KB)\n",
            "Trainable params: 93486 (365.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "56/56 [==============================] - 19s 225ms/step - loss: 2.6306 - accuracy: 0.0949 - val_loss: 2.6115 - val_accuracy: 0.1540\n",
            "Epoch 2/60\n",
            "56/56 [==============================] - 10s 180ms/step - loss: 2.5710 - accuracy: 0.1205 - val_loss: 2.4874 - val_accuracy: 0.1741\n",
            "Epoch 3/60\n",
            "56/56 [==============================] - 12s 223ms/step - loss: 2.4027 - accuracy: 0.1641 - val_loss: 2.2297 - val_accuracy: 0.2857\n",
            "Epoch 4/60\n",
            "56/56 [==============================] - 12s 211ms/step - loss: 2.1382 - accuracy: 0.2935 - val_loss: 1.9463 - val_accuracy: 0.3571\n",
            "Epoch 5/60\n",
            "56/56 [==============================] - 12s 207ms/step - loss: 1.8747 - accuracy: 0.3516 - val_loss: 1.6554 - val_accuracy: 0.4353\n",
            "Epoch 6/60\n",
            "56/56 [==============================] - 10s 184ms/step - loss: 1.5990 - accuracy: 0.4492 - val_loss: 1.3815 - val_accuracy: 0.5603\n",
            "Epoch 7/60\n",
            "56/56 [==============================] - 12s 223ms/step - loss: 1.3404 - accuracy: 0.5787 - val_loss: 1.1434 - val_accuracy: 0.7277\n",
            "Epoch 8/60\n",
            "56/56 [==============================] - 12s 223ms/step - loss: 1.1277 - accuracy: 0.6696 - val_loss: 0.9410 - val_accuracy: 0.7612\n",
            "Epoch 9/60\n",
            "56/56 [==============================] - 12s 211ms/step - loss: 0.9617 - accuracy: 0.7299 - val_loss: 0.7884 - val_accuracy: 0.7969\n",
            "Epoch 10/60\n",
            "56/56 [==============================] - 10s 181ms/step - loss: 0.8008 - accuracy: 0.7874 - val_loss: 0.6413 - val_accuracy: 0.8438\n",
            "Epoch 11/60\n",
            "56/56 [==============================] - 12s 213ms/step - loss: 0.6997 - accuracy: 0.8164 - val_loss: 0.5429 - val_accuracy: 0.8817\n",
            "Epoch 12/60\n",
            "56/56 [==============================] - 12s 224ms/step - loss: 0.5667 - accuracy: 0.8627 - val_loss: 0.5065 - val_accuracy: 0.8772\n",
            "Epoch 13/60\n",
            "56/56 [==============================] - 12s 206ms/step - loss: 0.5056 - accuracy: 0.8839 - val_loss: 0.4438 - val_accuracy: 0.8996\n",
            "Epoch 14/60\n",
            "56/56 [==============================] - 10s 184ms/step - loss: 0.4428 - accuracy: 0.8923 - val_loss: 0.3575 - val_accuracy: 0.8951\n",
            "Epoch 15/60\n",
            "56/56 [==============================] - 12s 212ms/step - loss: 0.3811 - accuracy: 0.9129 - val_loss: 0.3579 - val_accuracy: 0.9018\n",
            "Epoch 16/60\n",
            "56/56 [==============================] - 12s 214ms/step - loss: 0.4178 - accuracy: 0.9001 - val_loss: 0.3678 - val_accuracy: 0.9018\n",
            "Epoch 17/60\n",
            "56/56 [==============================] - 11s 199ms/step - loss: 0.3393 - accuracy: 0.9196 - val_loss: 0.2879 - val_accuracy: 0.9174\n",
            "Epoch 18/60\n",
            "56/56 [==============================] - 10s 185ms/step - loss: 0.3006 - accuracy: 0.9319 - val_loss: 0.3827 - val_accuracy: 0.8839\n",
            "Epoch 19/60\n",
            "56/56 [==============================] - 12s 214ms/step - loss: 0.3106 - accuracy: 0.9286 - val_loss: 0.3068 - val_accuracy: 0.9040\n",
            "Epoch 20/60\n",
            "56/56 [==============================] - 12s 222ms/step - loss: 0.2458 - accuracy: 0.9470 - val_loss: 0.2294 - val_accuracy: 0.9353\n",
            "Epoch 21/60\n",
            "56/56 [==============================] - 11s 190ms/step - loss: 0.2008 - accuracy: 0.9548 - val_loss: 0.2568 - val_accuracy: 0.9152\n",
            "Epoch 22/60\n",
            "56/56 [==============================] - 11s 201ms/step - loss: 0.1931 - accuracy: 0.9626 - val_loss: 0.2720 - val_accuracy: 0.9263\n",
            "Epoch 23/60\n",
            "56/56 [==============================] - 13s 225ms/step - loss: 0.2000 - accuracy: 0.9565 - val_loss: 0.2349 - val_accuracy: 0.9397\n",
            "Epoch 24/60\n",
            "56/56 [==============================] - 12s 224ms/step - loss: 0.1703 - accuracy: 0.9621 - val_loss: 0.1879 - val_accuracy: 0.9531\n",
            "Epoch 25/60\n",
            "56/56 [==============================] - 11s 202ms/step - loss: 0.1567 - accuracy: 0.9699 - val_loss: 0.2832 - val_accuracy: 0.9219\n",
            "Epoch 26/60\n",
            "56/56 [==============================] - 10s 183ms/step - loss: 0.2611 - accuracy: 0.9347 - val_loss: 0.3602 - val_accuracy: 0.8884\n",
            "Epoch 27/60\n",
            "56/56 [==============================] - 13s 226ms/step - loss: 0.2733 - accuracy: 0.9308 - val_loss: 0.2814 - val_accuracy: 0.9263\n",
            "Epoch 28/60\n",
            "56/56 [==============================] - 12s 223ms/step - loss: 0.2319 - accuracy: 0.9403 - val_loss: 0.2547 - val_accuracy: 0.9241\n",
            "Epoch 29/60\n",
            "56/56 [==============================] - 11s 195ms/step - loss: 0.1699 - accuracy: 0.9688 - val_loss: 0.2125 - val_accuracy: 0.9420\n",
            "18/18 [==============================] - 3s 79ms/step - loss: 0.1719 - accuracy: 0.9554\n",
            "\n",
            "Test accuracy: 0.9553571343421936\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(64, input_shape=(timesteps, features), return_sequences=True))\n",
        "model.add(keras.layers.LSTM(64, return_sequences=True))  # Additional LSTM layer\n",
        "model.add(keras.layers.LSTM(64))  # Additional LSTM layer\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.1))\n",
        "model.add(keras.layers.Dense(32, activation='relu'))  # Additional Dense layer\n",
        "model.add(keras.layers.Dropout(0.1))  # Additional Dropout layer\n",
        "model.add(keras.layers.Dense(14, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "# Define early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_validation, y_validation),\n",
        "                    batch_size=32,\n",
        "                    epochs=60,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"\")"
      ],
      "metadata": {
        "id": "9wbLxfONUca6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "path = \"/content/drive/MyDrive/emotion/TESS Toronto emotional speech set data/YAF_angry/YAF_bar_angry.wav\"\n",
        "audio, sr=librosa.load(path)\n",
        "mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=16)\n",
        "print(f\"Original MFCC shape: {mfccs.shape}\")\n",
        "features = mfccs.T\n",
        "print(f\"Transposed MFCC shape: {features.shape}\")\n",
        "timesteps = 129\n",
        "num_features = 16\n",
        "if features.shape[0] < timesteps:\n",
        "    pad_width = timesteps - features.shape[0]\n",
        "    features = np.pad(features, ((0, pad_width), (0, 0)), mode='constant')\n",
        "else:\n",
        "    features = features[:timesteps, :]\n",
        "\n",
        "# print(f\"Padded MFCC shape: {features.shape}\")\n",
        "features = features.reshape(1, timesteps, num_features)\n",
        "# print(f\"Final input shape: {features.shape}\")\n",
        "\n",
        "predictions = model.predict(features)\n",
        "predicted_label = np.argmax(predictions)\n",
        "predicted_class = speaker_folders[predicted_label]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xizxOIUWYgH",
        "outputId": "281e562c-8aad-4fc2-d9cb-102c49f16622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original MFCC shape: (16, 91)\n",
            "Transposed MFCC shape: (91, 16)\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Predicted class: YAF_angry\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Sd7swHXunxirrluztjBjDh1QApyhOZX6",
      "authorship_tag": "ABX9TyNZyI2WGqS4hQ8LtapEt7e+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}